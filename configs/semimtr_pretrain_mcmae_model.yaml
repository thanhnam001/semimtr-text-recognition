global:
  name: seqclr-pretrain-vision-model
  phase: train
  stage: pretrain-vision
  workdir: workdir
  seed: ~

dataset:
  scheme: selfsupervised
  type: ST
  resize_type: 'padded'
  train: {
    roots: [
        'data/hw/training/label',
        'data/hw/training/unlabel',
    ],
    # weights: ~,
    weights: [ 0.5, 0.5],
    batch_size: 2,
  }
  valid: {
    roots: [
        'data/hw/validation',
    ],
    batch_size: 2
  }
  test: {
    roots: [
        'data/hw/evaluation',
        # 'data/evaluation/addition',
    ],
    batch_size: 1
  }
  image: {
    height: 32,
    width: 512,
  }
  data_aug: True
  multiscales: False
  num_workers: 0
  augmentation_severity: 1
  case_sensitive: True
  space_as_token: True
  charset_path: 'data/charset_hw.txt'

training:
  epochs: 3
  show_iters: 3000
  eval_iters: 3000
  save_iters: 3000

optimizer:
  type: Adam
  true_wd: False
  wd: 0.0001
  bn_wd: False
  clip_grad: 20
  lr: 0.0001
  scheduler: {
    periods: [ 17, 5, 3 ],
    gamma: 0.1,
  }

model:
  name: 'semimtr.modules.model_seqclr_vision.SeqCLRModel'
  checkpoint: ~
  vision: {
    mcmae_checkpoint: workdir/bkai_mcmae-s_weight.pth,
    loss_weight: 1.,
    attention: 'position',
    backbone: 'mcmae',
    backbone_ln: 3,
    patch_size: [[2, 2],[2, 2],[2, 2]], 
    in_chans: 3,
    embed_dim: [256, 384, 768],
    depth: [2, 2, 7],
    num_heads: 6,
    mlp_ratio: [4, 4, 4],
    qkv_bias: False,
    qk_scale: ~,
    drop_rate: 0.,
    attn_drop_rate: 0.,
    drop_path_rate: 0.,
  }
  proj: {
    layer: backbone_feature,  # 'feature'|'backbone_feature'
    scheme: null,  # null|'bilstm'|'linear_per_column'
    # hidden: 256,
    # output: 256,
  }
  contrastive: {
    loss_weight: 1.,
    supervised_flag: True,
  }
  instance_mapping: {
    frame_to_instance: False,
    fixed: instances,  # instances|frames
    w: 5,
  }
